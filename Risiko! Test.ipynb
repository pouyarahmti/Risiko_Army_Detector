{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "880f2960",
   "metadata": {},
   "source": [
    "# <b>Deep Learning:</b> Risiko! Army detector\n",
    "\n",
    "---\n",
    "A.A. 2022/23 (6 CFU) - Dr. Daniel Fusaro Ph.D. Student\n",
    "\n",
    "---\n",
    "\n",
    "# Yolov7 test\n",
    "\n",
    "\n",
    "With this Jupyter Notebook you can:\n",
    " - test the accuracy of a pre-trained Yolov7 model on your custom dataset\n",
    " - get the performance metrics (that you need to include in your project report)\n",
    " - visualize the results\n",
    "\n",
    "---\n",
    "\n",
    "Risiko! game official Wikipedia page -\n",
    "[https://en.wikipedia.org/wiki/RisiKo!](https://en.wikipedia.org/wiki/RisiKo!)\n",
    "\n",
    "---\n",
    "\n",
    "### To run this Jupyter Notebook you will need\n",
    "\n",
    "#### run the following commands:\n",
    "```\n",
    "pip3 install torch torchvision\n",
    "pip3 install seaborn\n",
    "git clone https://github.com/WongKinYiu/yolov7\n",
    " ```\n",
    "#### follow these steps:\n",
    " - the weights of the pretrained model (see the Google Drive folder of the project)\n",
    " - the dataset produced by you (using Risiko! Synthetic Dataset Creator.ipynb)\n",
    " - the dataset of real images that you find in the Google Drive folder of the project\n",
    " - modify the coco_risiko.yaml config file: it must contain, in the \"test\" value, the path to the test.txt file containing all the test images path\n",
    " - produce the aforementioned test.txt file, like the one you find in the Google Drive folder (aka test_example.txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c15c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "\n",
    "import numpy as np\n",
    "import torch                    # if you don't have it, just \"pip3 install torch torchvision\"\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import yaml\n",
    "\n",
    "import sys\n",
    "sys.path.append('yolov7')\n",
    "\n",
    "# probably, you also must do \"pip3 install seaborn\"\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import create_dataloader\n",
    "from utils.general import coco80_to_coco91_class, check_dataset, check_file, check_img_size, check_requirements, \\\n",
    "    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr\n",
    "from utils.metrics import ap_per_class, ConfusionMatrix\n",
    "from utils.plots import plot_images, output_to_target, plot_study_txt\n",
    "from utils.torch_utils import select_device, time_synchronized, TracedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e5fe15",
   "metadata": {},
   "source": [
    "## The \"test\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292ff85",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def test(data,\n",
    "         weights=None,\n",
    "         batch_size=32,\n",
    "         imgsz=640,\n",
    "         conf_thres=0.001,\n",
    "         iou_thres=0.6,      # for NMS\n",
    "         save_json=False,\n",
    "         single_cls=False,\n",
    "         augment=False,\n",
    "         verbose=False,\n",
    "         model=None,\n",
    "         dataloader=None,\n",
    "         save_dir=Path(''),  # for saving images\n",
    "         save_txt=False,     # for auto-labelling\n",
    "         save_hybrid=False,  # for hybrid auto-labelling\n",
    "         save_conf=False,    # save auto-label confidences\n",
    "         plots=True,\n",
    "         wandb_logger=None,\n",
    "         compute_loss=None,\n",
    "         half_precision=True,\n",
    "         trace=False,\n",
    "         is_coco=False,\n",
    "         v5_metric=False):\n",
    "\n",
    "    set_logging()\n",
    "    device = select_device(opt.device, batch_size=batch_size)\n",
    "\n",
    "    # Directories\n",
    "    save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run\n",
    "    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    # Load model\n",
    "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "    gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n",
    "    imgsz = check_img_size(imgsz, s=gs)  # check img_size\n",
    "\n",
    "    if trace:\n",
    "        model = TracedModel(model, device, imgsz)\n",
    "\n",
    "    # Half\n",
    "    half = device.type != 'cpu' and half_precision  # half precision only supported on CUDA\n",
    "    if half:\n",
    "        model.half()\n",
    "\n",
    "    # Configure\n",
    "    model.eval()\n",
    "    if isinstance(data, str):\n",
    "        is_coco = data.endswith('coco.yaml')\n",
    "        with open(data) as f:\n",
    "            data = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    check_dataset(data)  # check\n",
    "    nc = 1 if single_cls else int(data['nc'])  # number of classes\n",
    "    iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
    "    niou = iouv.numel()\n",
    "\n",
    "    # Logging\n",
    "    log_imgs = 0\n",
    "    if wandb_logger and wandb_logger.wandb:\n",
    "        log_imgs = min(wandb_logger.log_imgs, 100)\n",
    "    # Dataloader\n",
    "    if device.type != 'cpu':\n",
    "        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
    "    task = opt.task if opt.task in ('train', 'val', 'test') else 'val'  # path to train/val/test images\n",
    "    dataloader = create_dataloader(data[task], imgsz, batch_size, gs, opt, pad=0.5, rect=True,\n",
    "                                   prefix=colorstr(f'{task}: '))[0]\n",
    "\n",
    "    if v5_metric:\n",
    "        print(\"Testing with YOLOv5 AP metric...\")\n",
    "    \n",
    "    seen = 0\n",
    "    confusion_matrix = ConfusionMatrix(nc=nc)\n",
    "    names = {k: v for k, v in enumerate(model.names if hasattr(model, 'names') else model.module.names)}\n",
    "    coco91class = coco80_to_coco91_class()\n",
    "    s = ('%20s' + '%12s' * 6) % ('Class', 'Images', 'Labels', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')\n",
    "    p, r, f1, mp, mr, map50, map, t0, t1 = 0., 0., 0., 0., 0., 0., 0., 0., 0.\n",
    "    loss = torch.zeros(3, device=device)\n",
    "    jdict, stats, ap, ap_class, wandb_images = [], [], [], [], []\n",
    "    for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc=s)):\n",
    "        img = img.to(device, non_blocking=True)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        targets = targets.to(device)\n",
    "        nb, _, height, width = img.shape  # batch size, channels, height, width\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Run model\n",
    "            t = time_synchronized()\n",
    "            out, train_out = model(img, augment=augment)  # inference and training outputs\n",
    "            t0 += time_synchronized() - t\n",
    "\n",
    "            # Compute loss\n",
    "            if compute_loss:\n",
    "                loss += compute_loss([x.float() for x in train_out], targets)[1][:3]  # box, obj, cls\n",
    "\n",
    "            # Run NMS\n",
    "            targets[:, 2:] *= torch.Tensor([width, height, width, height]).to(device)  # to pixels\n",
    "            lb = [targets[targets[:, 0] == i, 1:] for i in range(nb)] if save_hybrid else []  # for autolabelling\n",
    "\n",
    "            t = time_synchronized()\n",
    "            out = non_max_suppression(out, conf_thres=conf_thres, iou_thres=iou_thres, labels=lb, multi_label=True)\n",
    "            t1 += time_synchronized() - t\n",
    "\n",
    "        # Statistics per image\n",
    "        for si, pred in enumerate(out):\n",
    "            labels = targets[targets[:, 0] == si, 1:]\n",
    "            nl = len(labels)\n",
    "            tcls = labels[:, 0].tolist() if nl else []  # target class\n",
    "            path = Path(paths[si])\n",
    "            seen += 1\n",
    "\n",
    "            if len(pred) == 0:\n",
    "                if nl:\n",
    "                    stats.append((torch.zeros(0, niou, dtype=torch.bool), torch.Tensor(), torch.Tensor(), tcls))\n",
    "                continue\n",
    "\n",
    "            # Predictions\n",
    "            predn = pred.clone()\n",
    "            scale_coords(img[si].shape[1:], predn[:, :4], shapes[si][0], shapes[si][1])  # native-space pred\n",
    "            \n",
    "            if opt.print_bbox:\n",
    "                for line in predn:\n",
    "                    x, y, w, h, conf, cl = line.detach().cpu().float()\n",
    "                    print(f\"{int(x):<6.0f} {int(y):<6.0f} {int(w):<6.0f} {int(h):<6.0f} {conf:<6.4} {int(cl):<2d}\")\n",
    "            \n",
    "            opt.labels.append([predn, paths[si]])\n",
    "            \n",
    "            # Append to text file\n",
    "            if save_txt:\n",
    "                gn = torch.tensor(shapes[si][0])[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "                for *xyxy, conf, cls in predn.tolist():\n",
    "                    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                    line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n",
    "                    with open(save_dir / 'labels' / (path.stem + '.txt'), 'a') as f:\n",
    "                        f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "\n",
    "            # W&B logging - Media Panel Plots\n",
    "            if len(wandb_images) < log_imgs and wandb_logger.current_epoch > 0:  # Check for test operation\n",
    "                if wandb_logger.current_epoch % wandb_logger.bbox_interval == 0:\n",
    "                    box_data = [{\"position\": {\"minX\": xyxy[0], \"minY\": xyxy[1], \"maxX\": xyxy[2], \"maxY\": xyxy[3]},\n",
    "                                 \"class_id\": int(cls),\n",
    "                                 \"box_caption\": \"%s %.3f\" % (names[cls], conf),\n",
    "                                 \"scores\": {\"class_score\": conf},\n",
    "                                 \"domain\": \"pixel\"} for *xyxy, conf, cls in pred.tolist()]\n",
    "                    boxes = {\"predictions\": {\"box_data\": box_data, \"class_labels\": names}}  # inference-space\n",
    "                    wandb_images.append(wandb_logger.wandb.Image(img[si], boxes=boxes, caption=path.name))\n",
    "            wandb_logger.log_training_progress(predn, path, names) if wandb_logger and wandb_logger.wandb_run else None\n",
    "\n",
    "            # Append to pycocotools JSON dictionary\n",
    "            if save_json:\n",
    "                # [{\"image_id\": 42, \"category_id\": 18, \"bbox\": [258.15, 41.29, 348.26, 243.78], \"score\": 0.236}, ...\n",
    "                image_id = int(path.stem) if path.stem.isnumeric() else path.stem\n",
    "                box = xyxy2xywh(predn[:, :4])  # xywh\n",
    "                box[:, :2] -= box[:, 2:] / 2  # xy center to top-left corner\n",
    "                for p, b in zip(pred.tolist(), box.tolist()):\n",
    "                    jdict.append({'image_id': image_id,\n",
    "                                  'category_id': coco91class[int(p[5])] if is_coco else int(p[5]),\n",
    "                                  'bbox': [round(x, 3) for x in b],\n",
    "                                  'score': round(p[4], 5)})\n",
    "\n",
    "            # Assign all predictions as incorrect\n",
    "            correct = torch.zeros(pred.shape[0], niou, dtype=torch.bool, device=device)\n",
    "            if nl:\n",
    "                detected = []  # target indices\n",
    "                tcls_tensor = labels[:, 0]\n",
    "\n",
    "                # target boxes\n",
    "                tbox = xywh2xyxy(labels[:, 1:5])\n",
    "                scale_coords(img[si].shape[1:], tbox, shapes[si][0], shapes[si][1])  # native-space labels\n",
    "                if plots:\n",
    "                    confusion_matrix.process_batch(predn, torch.cat((labels[:, 0:1], tbox), 1))\n",
    "\n",
    "                # Per target class\n",
    "                for cls in torch.unique(tcls_tensor):\n",
    "                    ti = (cls == tcls_tensor).nonzero(as_tuple=False).view(-1)  # prediction indices\n",
    "                    pi = (cls == pred[:, 5]).nonzero(as_tuple=False).view(-1)  # target indices\n",
    "\n",
    "                    # Search for detections\n",
    "                    if pi.shape[0]:\n",
    "                        # Prediction to target ious\n",
    "                        ious, i = box_iou(predn[pi, :4], tbox[ti]).max(1)  # best ious, indices\n",
    "\n",
    "                        # Append detections\n",
    "                        detected_set = set()\n",
    "                        for j in (ious > iouv[0]).nonzero(as_tuple=False):\n",
    "                            d = ti[i[j]]  # detected target\n",
    "                            if d.item() not in detected_set:\n",
    "                                detected_set.add(d.item())\n",
    "                                detected.append(d)\n",
    "                                correct[pi[j]] = ious[j] > iouv  # iou_thres is 1xn\n",
    "                                if len(detected) == nl:  # all targets already located in image\n",
    "                                    break\n",
    "            # Append statistics (correct, conf, pcls, tcls)\n",
    "            stats.append((correct.cpu(), pred[:, 4].cpu(), pred[:, 5].cpu(), tcls))\n",
    "\n",
    "        # Plot images\n",
    "        if plots and batch_i < 3:\n",
    "            f = save_dir / f'test_batch{batch_i}_labels.jpg'  # labels\n",
    "            Thread(target=plot_images, args=(img, targets, paths, f, names), daemon=True).start()\n",
    "            f = save_dir / f'test_batch{batch_i}_pred.jpg'  # predictions\n",
    "            Thread(target=plot_images, args=(img, output_to_target(out), paths, f, names), daemon=True).start()\n",
    "\n",
    "    # Compute statistics\n",
    "    stats = [np.concatenate(x, 0) for x in zip(*stats)]  # to numpy\n",
    "    if len(stats) and stats[0].any():\n",
    "        p, r, ap, f1, ap_class = ap_per_class(*stats, plot=plots, v5_metric=v5_metric, save_dir=save_dir, names=names)\n",
    "        ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95\n",
    "        mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
    "        nt = np.bincount(stats[3].astype(np.int64), minlength=nc)  # number of targets per class\n",
    "    else:\n",
    "        nt = torch.zeros(1)\n",
    "\n",
    "    # Print results\n",
    "    pf = '%20s' + '%12i' * 2 + '%12.3g' * 4  # print format\n",
    "    print(pf % ('all', seen, nt.sum(), mp, mr, map50, map))\n",
    "\n",
    "    # Print results per class\n",
    "    if (verbose or nc < 50) and nc > 1 and len(stats):\n",
    "        for i, c in enumerate(ap_class):\n",
    "            print(pf % (names[c], seen, nt[c], p[i], r[i], ap50[i], ap[i]))\n",
    "\n",
    "    # Print speeds\n",
    "    t = tuple(x / seen * 1E3 for x in (t0, t1, t0 + t1)) + (imgsz, imgsz, batch_size)  # tuple\n",
    "    print('Speed: %.1f/%.1f/%.1f ms inference/NMS/total per %gx%g image at batch-size %g' % t)\n",
    "\n",
    "    # Plots\n",
    "    if plots:\n",
    "        confusion_matrix.plot(save_dir=save_dir, names=list(names.values()))\n",
    "        if wandb_logger and wandb_logger.wandb:\n",
    "            val_batches = [wandb_logger.wandb.Image(str(f), caption=f.name) for f in sorted(save_dir.glob('test*.jpg'))]\n",
    "            wandb_logger.log({\"Validation\": val_batches})\n",
    "    if wandb_images:\n",
    "        wandb_logger.log({\"Bounding Box Debugger/Images\": wandb_images})\n",
    "\n",
    "    # Save JSON\n",
    "    if save_json and len(jdict):\n",
    "        w = Path(weights[0] if isinstance(weights, list) else weights).stem if weights is not None else ''  # weights\n",
    "        anno_json = './coco/annotations/instances_val2017.json'  # annotations json\n",
    "        pred_json = str(save_dir / f\"{w}_predictions.json\")  # predictions json\n",
    "        print('\\nEvaluating pycocotools mAP... saving %s...' % pred_json)\n",
    "        with open(pred_json, 'w') as f:\n",
    "            json.dump(jdict, f)\n",
    "\n",
    "        try:  # https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb\n",
    "            from pycocotools.coco import COCO\n",
    "            from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "            anno = COCO(anno_json)  # init annotations api\n",
    "            pred = anno.loadRes(pred_json)  # init predictions api\n",
    "            eval = COCOeval(anno, pred, 'bbox')\n",
    "            if is_coco:\n",
    "                eval.params.imgIds = [int(Path(x).stem) for x in dataloader.dataset.img_files]  # image IDs to evaluate\n",
    "            eval.evaluate()\n",
    "            eval.accumulate()\n",
    "            eval.summarize()\n",
    "            map, map50 = eval.stats[:2]  # update results (mAP@0.5:0.95, mAP@0.5)\n",
    "        except Exception as e:\n",
    "            print(f'pycocotools unable to run: {e}')\n",
    "\n",
    "    # Return results\n",
    "    s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
    "    print(f\"Results saved to {save_dir}{s}\")\n",
    "    \n",
    "    maps = np.zeros(nc) + map\n",
    "    for i, c in enumerate(ap_class):\n",
    "        maps[c] = ap[i]\n",
    "    return (mp, mr, map50, map, *(loss.cpu() / len(dataloader)).tolist()), maps, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc6471",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opt:\n",
    "    data        = \"coco_risiko.yaml\"\n",
    "    weights     = \"pre_trained_weights/pre_trained_yolo_weights_v00.pt\" ##### PUT HERE the path to the weights of yolo (e.h. pre_trained_weights/pre_trained_yolo_weights_v00.pt)\n",
    "    \n",
    "    batch_size  = 1                           # size of each image batch\n",
    "    img_size    = 640                         # inference size (pixels)\n",
    "    conf_thres  = 0.2                         # object confidence threshold\n",
    "    iou_thres   = 0.65                        # IOU threshold for NMS\n",
    "    save_json   = False                       # save a cocoapi-compatible JSON results file\n",
    "    single_cls  = False\n",
    "    augment     = False\n",
    "    verbose     = False\n",
    "    save_txt    = False                        # save results to *.txt\n",
    "    save_hybrid = False                        # save label+prediction hybrid results to *.txt\n",
    "    save_conf   = False                        # save confidences in --save-txt labels\n",
    "    project     = \"runs/test\"                 \n",
    "    no_trace    = False                        # don`t trace model\n",
    "    v5_metric   = False                        # assume maximum recall as 1.0 in AP calculation\n",
    "    exist_ok    = False                        # existing project/name ok, do not increment\n",
    "    device      = \"0\"                         # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "    task        = \"test\"                      # \n",
    "    name        = \"yolov7_risiko_test\"        # save to project/name\n",
    "    \n",
    "    print_bbox  = False\n",
    "    \n",
    "    labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9456b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Opt()\n",
    "\n",
    "opt.data = check_file(opt.data)\n",
    "\n",
    "test(opt.data,\n",
    "     opt.weights,\n",
    "     opt.batch_size,\n",
    "     opt.img_size,\n",
    "     opt.conf_thres,\n",
    "     opt.iou_thres,\n",
    "     opt.save_json,\n",
    "     opt.single_cls,\n",
    "     opt.augment,\n",
    "     opt.verbose,\n",
    "     save_txt = opt.save_txt | opt.save_hybrid,\n",
    "     save_hybrid = opt.save_hybrid,\n",
    "     save_conf = opt.save_conf,\n",
    "     trace = not opt.no_trace,\n",
    "     v5_metric = opt.v5_metric\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c48c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('qtagg')\n",
    "\n",
    "for labels, image_path in opt.labels:\n",
    "    img = cv2.imread(image_path)\n",
    "    print(image_path)\n",
    "    for line in labels:\n",
    "        x, y, w, h, conf, cl = line.detach().cpu().float()\n",
    "        cv2.rectangle(img, (int(x), int(y)), (int(w), int(h)), (36,255,12, 1) if cl < 6 else (255,12,10, 1), 2)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
